{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Trabalho Final - Inteligência Computacional Aplicada (TIP7077) </b>\n",
    "#### <b> Aluno: Carlos Eduardo Sousa Lima </b>\n",
    "#### <b> Prof. Guilherme de Alencar Barreto </b>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Questão 01 - Classificação de Padrões - MNIST database of handwritten digits </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='text-align: justify;'>\n",
    "As classes e funções apresentadas no bloco de código abaixo foram comuns a todos os classificadores implementados. Nelas, estão implementadas a leitura dos dados, adequação da codificação do vetor de saída (alvo) e normalização dos dados. A seguir, cada uma delas é melhor descrita:\n",
    "</div>\n",
    "\n",
    "- MNIST_data:<br>\n",
    "    <div style='text-align: justify;'>\n",
    "    \n",
    "    Essa classe foi criada para conter as funções de aquisição dos dados de treino <b>get_train_data()</b> e dados de teste <b>get_test_data()</b>. Essas funções utilizam a biblioteca mnist (#https://pypi.org/project/python-mnist/#description), a qual, a partir dos dados obtidos em http://yann.lecun.org/exdb/mnist/index.html, descomprime e transforma-os em um objeto Numpy Array (np.array). Cada uma dessas funções retornam dois objetos np.array, um com os dados de entrada e o outro com seus respectivos labels. Os dados de entrada são retornados de forma vetorizada, ou seja, a matriz $28{\\times}28$ é empilhada dando origem a um vetor $784{\\times}1$. Os labels são o valor inteiro entre 0 e 9 que esse vetor representa.\n",
    "\n",
    "    Cabe destacar que a base de dados de treino possuem 60.000 elementos e a de teste 10.000 elementos. Dessa forma, os dados de entrada formam uma matriz $60.000{\\times}738$, para a base de treino, e $10.000{\\times}738$, para a base de teste. Os labels, por sua vez, forma um vetor de $60.000{\\times}1$, para a base de treino, e $10.000{\\times}1$, para a base de teste</div>\n",
    "\n",
    "    <div style='text-align: justify;' class=\"alert alert-block alert-info\">\n",
    "    \n",
    "    Nota-se que cada elemento representa uma linha e suas características são ordenadas ao longo de suas colunas, o que diverge da ordenação empregada ao longo da disciplina. Optou-se por manter essa ordenação, assim, algumas operações matriciais podem apresentar uma ordem contrária à apresentada nas notas de aula, por exemplo:\n",
    "\n",
    "    $\\vec{y} = \\tilde{W} \\cdot \\vec{x}$ (notas de aula)<br> \n",
    "    $\\vec{y} = \\vec{x} \\cdot \\tilde{W}$ (seguindo a notação adotada no trabalho)\n",
    "    </div>\n",
    "\n",
    "\n",
    "- one_hot_enconding():\n",
    "    <div style='text-align: justify;'>\n",
    "        \n",
    "    Essa função altera o formato do vetor labels. Para cada elemento da base de dados de entrada do MNIST, seja a de treino ou de teste, existirá um label que representará o valor associado a esse elemento da base de dados. Tomando como exemplo os dados de treino, sua base de dados terá dimensão $60.000{\\times}738$, visto que o procedimento de obtenção dos dados retorna esses dados de forma vetorizada. No caso dos seu respectivo vetor de label ($\\vec{y}$), ele terá dimensão $60.000{\\times}1$.\n",
    "\n",
    "    Os possíveis valores de cada um dos elementos contidos no vetor de labels são representados por $x \\in [0,9]$, tal que $x \\in \\Z$. A função aqui descrita, portanto, cria uma nova codificação para os labels baseada na codificação one-hot. Como $x$ pode assumir 10 valores (classes), cada elemento do vetor de labels dará origem a um vetor de cardinalidade igual 10. Portanto, após a aplicação dessa função, o vetor de label $\\vec{y}$ passará a ter dimensão $60.000{\\times}10$, para a base de treino, e $10.000{\\times}10$, para a base de teste. \n",
    "\n",
    "    Esse vetor terá valor igual a 1 no índice que coincide com o valor representando no respectivo elemento do vetor de labels original, nos demais índices receberá o valor 0. Exemplificando, após a utilização da função one_hot_enconding(): <br>\n",
    "    \n",
    "    - $0 \\rightarrow [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]$ <br>\n",
    "    - $1 \\rightarrow [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]$ <br>\n",
    "    - $ \\,\\vdots \\rightarrow \\quad\\quad\\quad\\quad\\,\\, \\vdots$ <br>\n",
    "    - $9 \\rightarrow [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]$ <br>\n",
    "    \n",
    "    A utilização dessa codificação é interessante, pois assume que os vetores que representam cada classe são ortogonais entre si, ou seja, mutuamente exclusivos. \n",
    "    </div>\n",
    "\n",
    "\n",
    "- norm_data():\n",
    "    <div style='text-align: justify;'>\n",
    "\n",
    "    A MNIST *database of handwritten digits* consiste na representação matricial de imagens de caracteres cursivos. Nessa representação, utiliza-se matrizes quadradas de dimensão $28{\\times}28$, ou seja, cada imagem contém 784 pixels. Em cada um desses pixels, representasse uma tonalidade de cinza, considerando uma escala em que zero é totalmente branco e 255 totalmente preto.\n",
    "\n",
    "    Como supracitado, cada uma dessas matrizes de dados são vetorizadas nas presente analises, dando origem a um vetor de dimensão $1{\\times}p$. Agrupando esses vetores em linhas, obtém-se a matriz de dados de dimensão $n{\\times}p$ utilizada nesse trabalho, sendo $n$ o número de imagens disponibilizadas para treino ou teste e $p = 784$. \n",
    "\n",
    "    A função nomr_data() atua normalizando os valores da escala de tons de cinza associados aos pixels das imagens de caracteres cursivos. Em outras palavras, para cada $n$ elemento da matriz de dados, seja de treino ou de teste, essa função varia intervalo de variação dos valores de $[0,255]$ para $[0,1]$. O processo de normalização é amplamente recomendado para algoritmos de classificação baseado em aprendizado, pois dados de entrada com elevados valores, ou que suas variáveis apresentem grandes diferença na magnitude dos seus valores, podem prejudicar o processo de aprendizado. Para normalização desses dados, adotou-se a seguinte equação:\n",
    "\n",
    "    $$\n",
    "        x^{norm}_{j} = \\frac{x_{j} - x^{max}_{j}}{x^{max}_{j} - x^{min}_{j}}\n",
    "    $$\n",
    "    </div>\n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mnist import MNIST #https://pypi.org/project/python-mnist/#description\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class MNIST_data():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_train_data():\n",
    "        \n",
    "        mndata = MNIST(\"./\")\n",
    "        mndata.gz = True\n",
    "        x, y = mndata.load_training()\n",
    "\n",
    "        return (np.array(x), np.array(y))\n",
    "    \n",
    "    def get_test_data():\n",
    "        \n",
    "        mndata = MNIST(\"./\")\n",
    "        mndata.gz = True\n",
    "        x, y = mndata.load_testing()\n",
    "\n",
    "        return (np.array(x), np.array(y))\n",
    "\n",
    "def one_hot_enconding(y, n):\n",
    "\n",
    "    y_enc = np.zeros((y.shape[0], n))\n",
    "    for i in range(y.shape[0]):\n",
    "        y_enc[i, y[i]] = 1\n",
    "\n",
    "    return y_enc\n",
    "\n",
    "def norm_data(df):\n",
    "    df_std = np.zeros(df.shape)\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        # df_std[i,:] = (df[i,:] - df[i,:].mean())/(df[i,:].std(ddof = std_ddof))\n",
    "        df_std[i,:] = (df[i,:] - df[i,:].min())/(df[i,:].max() - df[i,:].min())\n",
    "    return df_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classificador Linear de Mínimos Quadrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de dados de Posto Incompleto\n",
      "\n",
      "Taxa de acerto Média = 85.34% \n",
      "\n",
      "Taxa de erro Média = 14.66% \n",
      "\n",
      "Melhor Taxa de Acerto = 85.41% \n",
      "\n",
      "Pior Taxa de Acerto = 85.32% \n",
      "\n",
      "Desv. Pad. Taxa de Acerto = 0.03%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# O código está utilizando a orientação nxp\n",
    "# n é o número de amostras, p o número de característica\n",
    "# As operações matriciais apresentam ordem contrária ao apresentando nas notas de aula\n",
    "# Y = W*X (Nota de Aula) - Y = X*W (Presente Código)\n",
    "\n",
    "Nr = 10\n",
    "X, Y = MNIST_data.get_train_data()\n",
    "X_test, Y_test = MNIST_data.get_test_data()\n",
    "    \n",
    "if np.linalg.matrix_rank(X) == min(X.shape):\n",
    "    print(\"Matrix de dados de Posto Completo\")\n",
    "else:\n",
    "    print(\"Matriz de dados de Posto Incompleto\")\n",
    "\n",
    "Y = one_hot_enconding(Y, 10)\n",
    "Y_test = one_hot_enconding(Y_test, 10)\n",
    "\n",
    "X = norm_data(X)\n",
    "X_test = norm_data(X_test)\n",
    "\n",
    "tx_ok = np.zeros(Nr)\n",
    "for i in range(Nr):\n",
    "    rand_index = np.random.permutation(X.shape[0])\n",
    "    X = X[rand_index,:]\n",
    "    Y = Y[rand_index,:]\n",
    "\n",
    "    if X.shape[0] != X.shape[1]:\n",
    "        W = np.linalg.lstsq(X,Y)[0]\n",
    "    else:\n",
    "        W = np.linalg.solve(X,Y)[0]\n",
    "\n",
    "    Y_mod = np.dot(X_test, W)\n",
    "\n",
    "    count_ok = 0\n",
    "\n",
    "    for j in range(Y_mod.shape[0]):\n",
    "        if Y_mod[j,:].argmax() == Y_test[j,:].argmax():\n",
    "            count_ok += 1\n",
    "    \n",
    "    tx_ok[i] = count_ok/Y_mod.shape[0]\n",
    "\n",
    "print('''\n",
    "Taxa de acerto Média = {:.2%} \\n\n",
    "Taxa de erro Média = {:.2%} \\n\n",
    "Melhor Taxa de Acerto = {:.2%} \\n\n",
    "Pior Taxa de Acerto = {:.2%} \\n\n",
    "Desv. Pad. Taxa de Acerto = {:.2%}\n",
    "'''.format(tx_ok.mean(), 1-tx_ok.mean(),\n",
    "    tx_ok.max(), tx_ok.min(), tx_ok.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "S2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "S2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "S2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "S2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
