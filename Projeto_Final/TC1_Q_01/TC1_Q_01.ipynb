{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Trabalho Final - Inteligência Computacional Aplicada (TIP7077) </b>\n",
    "#### <b> Aluno: Carlos Eduardo Sousa Lima </b>\n",
    "#### <b> Prof. Guilherme de Alencar Barreto </b>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Questão 01 - Classificação de Padrões - MNIST database of handwritten digits </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='text-align: justify;'>\n",
    "As classes e funções apresentadas no bloco de código abaixo foram comuns a todos os classificadores implementados. Nelas, estão implementadas a leitura dos dados, adequação da codificação do vetor de saída (alvo) e normalização dos dados. A seguir, cada uma delas é melhor descrita:\n",
    "</div>\n",
    "\n",
    "- MNIST_data:<br>\n",
    "    <div style='text-align: justify;'>\n",
    "    \n",
    "    Essa classe foi criada para conter as funções de aquisição dos dados de treino <b>get_train_data()</b> e dados de teste <b>get_test_data()</b>. Essas funções utilizam a biblioteca mnist (#https://pypi.org/project/python-mnist/#description), a qual, a partir dos dados obtidos em http://yann.lecun.org/exdb/mnist/index.html, descomprime e transforma-os em um objeto Numpy Array (np.array). Cada uma dessas funções retornam dois objetos np.array, um com os dados de entrada e o outro com seus respectivos labels. Os dados de entrada são retornados de forma vetorizada, ou seja, a matriz $28{\\times}28$ é empilhada dando origem a um vetor $784{\\times}1$. Os labels são o valor inteiro entre 0 e 9 que esse vetor representa.\n",
    "\n",
    "    Cabe destacar que a base de dados de treino possuem 60.000 elementos e a de teste 10.000 elementos. Dessa forma, os dados de entrada formam uma matriz $60.000{\\times}738$, para a base de treino, e $10.000{\\times}738$, para a base de teste. Os labels, por sua vez, forma um vetor de $60.000{\\times}1$, para a base de treino, e $10.000{\\times}1$, para a base de teste</div>\n",
    "\n",
    "    <div style='text-align: justify;' class=\"alert alert-block alert-info\">\n",
    "    \n",
    "    Nota-se que cada elemento representa uma linha e suas características são ordenadas ao longo de suas colunas, o que diverge da ordenação empregada ao longo da disciplina. Optou-se por manter essa ordenação, assim, algumas operações matriciais podem apresentar uma ordem contrária à apresentada nas notas de aula, por exemplo:\n",
    "\n",
    "    $\\vec{y} = \\tilde{W} \\cdot \\vec{x}$ (notas de aula)<br> \n",
    "    $\\vec{y} = \\vec{x} \\cdot \\tilde{W}$ (seguindo a notação adotada no trabalho)\n",
    "    </div>\n",
    "\n",
    "\n",
    "- one_hot_enconding():\n",
    "    <div style='text-align: justify;'>\n",
    "        \n",
    "    Essa função altera o formato do vetor labels. Para cada elemento da base de dados de entrada do MNIST, seja a de treino ou de teste, existirá um label que representará o valor associado a esse elemento da base de dados. Tomando como exemplo os dados de treino, sua base de dados terá dimensão $60.000{\\times}738$, visto que o procedimento de obtenção dos dados retorna esses dados de forma vetorizada. No caso dos seu respectivo vetor de label ($\\vec{y}$), ele terá dimensão $60.000{\\times}1$.\n",
    "\n",
    "    Os possíveis valores de cada um dos elementos contidos no vetor de labels são representados por $x \\in [0,9]$, tal que $x \\in \\Z$. A função aqui descrita, portanto, cria uma nova codificação para os labels baseada na codificação one-hot. Como $x$ pode assumir 10 valores (classes), cada elemento do vetor de labels dará origem a um vetor de cardinalidade igual 10. Portanto, após a aplicação dessa função, o vetor de label $\\vec{y}$ passará a ter dimensão $60.000{\\times}10$, para a base de treino, e $10.000{\\times}10$, para a base de teste. \n",
    "\n",
    "    Esse vetor terá valor igual a 1 no índice que coincide com o valor representando no respectivo elemento do vetor de labels original, nos demais índices receberá o valor 0. Exemplificando, após a utilização da função one_hot_enconding(): <br>\n",
    "    \n",
    "    - $0 \\rightarrow [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]$ <br>\n",
    "    - $1 \\rightarrow [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]$ <br>\n",
    "    - $ \\,\\vdots \\rightarrow \\quad\\quad\\quad\\quad\\,\\, \\vdots$ <br>\n",
    "    - $9 \\rightarrow [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]$ <br>\n",
    "    \n",
    "    A utilização dessa codificação é interessante, pois assume que os vetores que representam cada classe são ortogonais entre si, ou seja, mutuamente exclusivos. \n",
    "    </div>\n",
    "\n",
    "\n",
    "- norm_data():\n",
    "    <div style='text-align: justify;'>\n",
    "\n",
    "    A MNIST *database of handwritten digits* consiste na representação matricial de imagens de caracteres cursivos. Nessa representação, utiliza-se matrizes quadradas de dimensão $28{\\times}28$, ou seja, cada imagem contém 784 pixels. Em cada um desses pixels, representasse uma tonalidade de cinza, considerando uma escala em que zero é totalmente branco e 255 totalmente preto.\n",
    "\n",
    "    Como supracitado, cada uma dessas matrizes de dados são vetorizadas nas presente analises, dando origem a um vetor de dimensão $1{\\times}p$. Agrupando esses vetores em linhas, obtém-se a matriz de dados de dimensão $n{\\times}p$ utilizada nesse trabalho, sendo $n$ o número de imagens disponibilizadas para treino ou teste e $p = 784$. \n",
    "\n",
    "    A função nomr_data() atua normalizando os valores da escala de tons de cinza associados aos pixels das imagens de caracteres cursivos. Em outras palavras, para cada $n$ elemento da matriz de dados, seja de treino ou de teste, essa função varia intervalo de variação dos valores de $[0,255]$ para $[0,1]$. O processo de normalização é amplamente recomendado para algoritmos de classificação baseado em aprendizado, pois dados de entrada com elevados valores, ou que suas variáveis apresentem grandes diferença na magnitude dos seus valores, podem prejudicar o processo de aprendizado. Para normalização desses dados, adotou-se a seguinte equação:\n",
    "\n",
    "    $$\n",
    "        x^{norm}_{j} = \\frac{x_{j} - x^{max}_{j}}{x^{max}_{j} - x^{min}_{j}}\n",
    "    $$\n",
    "    </div>\n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mnist import MNIST #https://pypi.org/project/python-mnist/#description\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class MNIST_data():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_train_data():\n",
    "        \n",
    "        mndata = MNIST(\"./\")\n",
    "        mndata.gz = True\n",
    "        x, y = mndata.load_training()\n",
    "\n",
    "        return (np.array(x), np.array(y))\n",
    "    \n",
    "    def get_test_data():\n",
    "        \n",
    "        mndata = MNIST(\"./\")\n",
    "        mndata.gz = True\n",
    "        x, y = mndata.load_testing()\n",
    "\n",
    "        return (np.array(x), np.array(y))\n",
    "\n",
    "def one_hot_enconding(y, n):\n",
    "\n",
    "    y_enc = np.zeros((y.shape[0], n))\n",
    "    for i in range(y.shape[0]):\n",
    "        y_enc[i, y[i]] = 1\n",
    "\n",
    "    return y_enc\n",
    "\n",
    "def norm_data(df):\n",
    "    df_std = np.zeros(df.shape)\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        # df_std[i,:] = (df[i,:] - df[i,:].mean())/(df[i,:].std(ddof = std_ddof))\n",
    "        df_std[i,:] = (df[i,:] - df[i,:].min())/(df[i,:].max() - df[i,:].min())\n",
    "    return df_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avaliando o posto das matrizes dos dados de treino (X) e dados de teste (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de entrada (X) - Matriz de Posto Incompleto\n",
      "\n",
      "Dados de entrada (X_test) - Matriz de Posto Incompleto\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, Y = MNIST_data.get_train_data()\n",
    "X_test, Y_test = MNIST_data.get_test_data()\n",
    "    \n",
    "if np.linalg.matrix_rank(X) == min(X.shape):\n",
    "    print(\"Dados de entrada (X) - Matriz de Posto Completo\\n\")\n",
    "else:\n",
    "    print(\"Dados de entrada (X) - Matriz de Posto Incompleto\\n\")\n",
    "if np.linalg.matrix_rank(X_test) == min(X_test.shape):\n",
    "    print(\"Dados de entrada (X_test) - Matriz de Posto Completo\\n\")\n",
    "else:\n",
    "    print(\"Dados de entrada (X_test) - Matriz de Posto Incompleto\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classificador Linear de Mínimos Quadrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodada 1 - Taxa de Acerto = 85.32%\n",
      "Rodada 2 - Taxa de Acerto = 85.28%\n",
      "Rodada 3 - Taxa de Acerto = 85.32%\n",
      "Rodada 4 - Taxa de Acerto = 85.32%\n",
      "Rodada 5 - Taxa de Acerto = 85.31%\n",
      "\n",
      "Taxa de acerto Média = 85.31%\n",
      "Taxa de erro Média = 14.69%\n",
      "Melhor Taxa de Acerto = 85.32%\n",
      "Pior Taxa de Acerto = 85.28%\n",
      "Desv. Pad. Taxa de Acerto = 0.02%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# O código está utilizando a orientação nxp\n",
    "# n é o número de amostras, p o número de característica\n",
    "# As operações matriciais apresentam ordem contrária ao apresentando nas notas de aula\n",
    "# Y = W*X (Nota de Aula) - Y = X*W (Presente Código)\n",
    "\n",
    "Nr = 5\n",
    "X, Y = MNIST_data.get_train_data()\n",
    "X_test, Y_test = MNIST_data.get_test_data()\n",
    "    \n",
    "Y = one_hot_enconding(Y, 10)\n",
    "Y_test = one_hot_enconding(Y_test, 10)\n",
    "\n",
    "X = norm_data(X)\n",
    "X_test = norm_data(X_test)\n",
    "\n",
    "tx_ok = np.zeros(Nr)\n",
    "for r in range(Nr):\n",
    "    rand_index = np.random.permutation(X.shape[0])\n",
    "    X = X[rand_index,:]\n",
    "    Y = Y[rand_index,:]\n",
    "\n",
    "    if X.shape[0] != X.shape[1]:\n",
    "        W = np.linalg.lstsq(X,Y)[0]\n",
    "    else:\n",
    "        W = np.linalg.solve(X,Y)[0]\n",
    "\n",
    "\n",
    "    Y_mod = np.dot(X_test, W)\n",
    "    count_ok = 0\n",
    "\n",
    "    for j in range(Y_mod.shape[0]):\n",
    "        if Y_mod[j,:].argmax() == Y_test[j,:].argmax():\n",
    "            count_ok += 1\n",
    "    \n",
    "    tx_ok[r] = count_ok/Y_mod.shape[0]\n",
    "    print(\"Rodada {} - Taxa de Acerto = {:.2%}\".format(r+1, tx_ok[r]))\n",
    "\n",
    "print('''\n",
    "Taxa de acerto Média = {:.2%}\n",
    "Taxa de erro Média = {:.2%}\n",
    "Melhor Taxa de Acerto = {:.2%}\n",
    "Pior Taxa de Acerto = {:.2%}\n",
    "Desv. Pad. Taxa de Acerto = {:.2%}\n",
    "'''.format(tx_ok.mean(), 1-tx_ok.mean(),\n",
    "    tx_ok.max(), tx_ok.min(), tx_ok.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='text-align: justify;'>\n",
    "    \n",
    "De acordo com LeCun *et al.* (1998), o classificador linear baseado em uma rede neural de uma camada (*1-layer NN*), Perceptron Simples???, obteve uma taxa de erro de 12.00% com a base de dados de teste, considerando nenhum pré-processamento desses dados.\n",
    "\n",
    "O Classificador Linear de Mínimos Quadrados (CLMQ), por sua vez, apresenta um desempenho similar, com uma taxa de erro média de 14.67%. O desempenho desse classificado foi considerado satisfatório e evidencia que esse problema de classificação pode ser resolvido satisfatoriamente por uma superfície de decisão linear, ou seja, um problema linearmente separável.\n",
    "\n",
    "Destaca-se que a operação para determinação da matriz $\\tilde{W}$ utilizou o método de eliminação de Gauss, não sendo necessário a inversão explícita de $\\tilde{X}\\tilde{X}^{T}$. Como apresentado, as matrizes de dados de entrada para treino e teste possuem posto incompleto, logo haveria problema nessa inversão explícita supracitada.\n",
    "\n",
    "Destaca-se, também, que o método de eliminação de Gauss possui um menor custo de processamento, sendo eficiente para dados de alta dimensão, como os utilizados no presente trabalho.\n",
    "\n",
    "<div>\n",
    "\n",
    "<div style='text-align: justify;'>\n",
    "<font size=\"2.5\">\n",
    "LeCu, Y.; Bottou, L.; Bengio, Y. and Haffner, P. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998.\n",
    "</font>\n",
    "<div>\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perceptron Logístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodada 1 - Taxa de acerto = 91.68%\n",
      "\n",
      "Taxa de acerto Média = 91.68%\n",
      "Taxa de erro Média = 8.32%\n",
      "Melhor Taxa de Acerto = 91.68%\n",
      "Pior Taxa de Acerto = 91.68%\n",
      "Desv. Pad. Taxa de Acerto = 0.00%\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def act_fun(u, fun):\n",
    "\n",
    "    if fun == \"step\":\n",
    "        u[np.where(u >= 0)] = 1\n",
    "        u[np.where(u < 0)] = 0\n",
    "\n",
    "    elif fun == \"tanh\":\n",
    "        u = np.array(list(map(lambda x: (1-np.exp(-x))/(1+np.exp(-x)), u)))\n",
    "    \n",
    "    elif fun == \"log\":\n",
    "        u = np.array(list(map(lambda x: 1/(1+np.exp(-x)), u)))\n",
    "    \n",
    "    return u \n",
    "\n",
    "# O código está utilizando a orientação nxp\n",
    "# n é o número de amostras, p o número de característica\n",
    "# As operações matriciais apresentam ordem contrária ao apresentando nas notas de aula\n",
    "# Y = W*X (Nota de Aula) - Y = X*W (Presente Código)\n",
    "\n",
    "X, Y = MNIST_data.get_train_data()\n",
    "X_test, Y_test = MNIST_data.get_test_data()\n",
    "    \n",
    "Y = one_hot_enconding(Y, 10)\n",
    "Y_test = one_hot_enconding(Y_test, 10)\n",
    "\n",
    "X = norm_data(X)\n",
    "X_test = norm_data(X_test)\n",
    "\n",
    "Nr = 1\n",
    "fun_type = \"log\"\n",
    "eta = 0.01\n",
    "Ne = 15\n",
    "tx_ok = np.empty((Nr))\n",
    "best_run = {\"Acc\": 0, \"RMSE\": 0, \"W\": 0}\n",
    "worst_run = {\"Acc\": 1, \"RMSE\": 0, \"W\": 0}\n",
    "if fun_type == \"tanh\":\n",
    "    #codificação da saída fica -1 e 1 para tangente hiperbólica\n",
    "    Y[Y == 0] = -1\n",
    "    Y_test[Y == 0] = -1\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for r in range(Nr):\n",
    "    #Não embaralhei a cada rodada, pois os dados de treino sempre serão X e Y\n",
    "    #Assim, como não haverá split do conjunto em dados de treino e teste\n",
    "    #Decidi embaralhar só dentro de cada época\n",
    "    #Inicialização aleatória dos pesos\n",
    "\n",
    "    W = np.random.rand(Y.shape[1], X.shape[1]+1)\n",
    "    RMSE_ep = np.full(Ne, np.nan)\n",
    "    \n",
    "    for ep in range(Ne):\n",
    "        #Embaralhamento da matriz de dados saída\n",
    "        rand_index = np.random.permutation(X.shape[0])\n",
    "        X = X[rand_index, :]\n",
    "        Y = Y[rand_index, :]\n",
    "        RMSE = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            x = np.append(-1, X[i,:]) #add bias\n",
    "            U = np.dot(W, x)\n",
    "            y = act_fun(U, fun_type)\n",
    "            err = Y[i,:] - y\n",
    "\n",
    "            x = np.expand_dims(x, 1)\n",
    "            err = np.expand_dims(err, 1)\n",
    "\n",
    "            RMSE = RMSE + 0.5*np.power(err, 2).sum()\n",
    "            W = W + eta*np.dot(err, x.T)\n",
    "        \n",
    "        RMSE_ep[ep] = RMSE/X.shape[0]\n",
    "\n",
    "    ax.plot(RMSE_ep)\n",
    "\n",
    "    count = 0\n",
    "    for j in range(X_test.shape[0]):\n",
    "        x = np.append(-1, X_test[j,:])\n",
    "        U = np.dot(W, x)\n",
    "        y = act_fun(U, fun_type)\n",
    "\n",
    "        if Y_test[j,:].argmax() == y.argmax():\n",
    "            count += 1\n",
    "\n",
    "    tx_ok[r] = count/X_test.shape[0]\n",
    "\n",
    "    print(\"Rodada {} - Taxa de acerto = {:.2%}\".format(r+1, tx_ok[r]))\n",
    "\n",
    "    if tx_ok[r] > best_run[\"Acc\"]:\n",
    "        best_run[\"Acc\"], best_run[\"RMSE\"], best_run[\"W\"] = (tx_ok[r], RMSE_ep, W)\n",
    "\n",
    "\n",
    "    if tx_ok[r] < worst_run[\"Acc\"]:\n",
    "        worst_run[\"Acc\"], worst_run[\"RMSE\"], worst_run[\"W\"] = (tx_ok[r], RMSE_ep, W)\n",
    "\n",
    "ax.plot(best_run[\"RMSE\"], label = \"Melhor rodada\", c = \"darkgreen\")\n",
    "ax.plot(worst_run[\"RMSE\"], label = \"Pior rodada\", c = \"red\")\n",
    "ax.set_ylabel(\"RMSE\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.legend()\n",
    "print('''\n",
    "Taxa de acerto Média = {:.2%}\n",
    "Taxa de erro Média = {:.2%}\n",
    "Melhor Taxa de Acerto = {:.2%}\n",
    "Pior Taxa de Acerto = {:.2%}\n",
    "Desv. Pad. Taxa de Acerto = {:.2%}\n",
    "'''.format(tx_ok.mean(), 1-tx_ok.mean(),\n",
    "    tx_ok.max(), tx_ok.min(), tx_ok.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14524289 0.09672172 0.09144827 0.08870541 0.08722094 0.08613941\n",
      " 0.08529313 0.08419684 0.08389694 0.08334575 0.08256829 0.08244846\n",
      " 0.08228141 0.0818618  0.08169757 0.08144612 0.08119435 0.08098104\n",
      " 0.08106622 0.08077524 0.08077238 0.0805767  0.08035836 0.08016898\n",
      " 0.0799892  0.08020665 0.07998921 0.08002224 0.0794258  0.07977588\n",
      " 0.07976768 0.07936634 0.07939778 0.07961154 0.0796241  0.07927355\n",
      " 0.07911501 0.07936106 0.07914394 0.07919197 0.07910841 0.07905815\n",
      " 0.07880537 0.07898826 0.07897827 0.07866818 0.07874927 0.07891939\n",
      " 0.07874519 0.07860309]\n"
     ]
    }
   ],
   "source": [
    "print(RMSE_ep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "S2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "S2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "S2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "S2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
