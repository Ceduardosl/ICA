{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Trabalho Final - Inteligência Computacional Aplicada (TIP7077) </b>\n",
    "#### <b> Aluno: Carlos Eduardo Sousa Lima </b>\n",
    "#### <b> Prof. Guilherme de Alencar Barreto </b>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Questão 02 - Regressão e Ajuste de Curvas - *Real estate valuation dataset* </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set was randomly split into the training data set (2/3 samples) and the testing data set (1/3 samples). (https://archive.ics.uci.edu/dataset/477/real+estate+valuation+data+set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas Utilizadas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regressão Linear Múltipla de Mínimos Quadrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Resumo das 20 Rodadas ######\n",
      "Taxa de acerto para uma taxa de erro admssível de 20%:\n",
      "Média = 68.62%, \n",
      "Desv. Pad. = 4.44%, \n",
      "Máximo = 78.99%, \n",
      "Mínimo = 60.87%\n",
      "\n",
      "Taxa de acerto para uma taxa de erro admssível de 10%:\n",
      "Média = 39.02%, \n",
      "Desv. Pad. = 3.31%, \n",
      "Máximo = 46.38%, \n",
      "Mínimo = 35.51%\n",
      "\n",
      "R2:\n",
      "Média = 0.561, \n",
      "Desv. Pad. = 0.067, \n",
      "Máximo = 0.663, \n",
      "Mínimo = 0.428\n",
      "\n",
      "RMSE:\n",
      "Média = 9.044, \n",
      "Desv. Pad. = 1.110, \n",
      "Máximo = 11.068, \n",
      "Mínimo = 7.447\n",
      "\n",
      "###### Melhor Rodada em relação as taxas de acerto para erros admissíveis de 10% e 20% ######\n",
      "Taxa de acerto para uma taxa de erro admssível de 20% = 78.99%\n",
      "Taxa de acerto para uma taxa de erro admssível de 10% = 42.75%\n",
      "R2 = 0.630\n",
      "RMSE = 8.032\n"
     ]
    }
   ],
   "source": [
    "def R2(y_true, y_pred):\n",
    "\n",
    "    coef = 1 - (np.power(y_true-y_pred,2).sum()/np.power(y_true-y_true.mean(),2).sum())\n",
    "\n",
    "    return coef\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "\n",
    "    coef = np.power((np.power(y_true - y_pred, 2).sum())/y_true.shape[0], 0.5)\n",
    "\n",
    "    return coef\n",
    "\n",
    "data = pd.read_excel(\"Real estate valuation data set.xlsx\", index_col = 0)\n",
    "\n",
    "X = data.iloc[:, 0:6].to_numpy()\n",
    "\n",
    "Y = data.iloc[:, -1].to_numpy()\n",
    "\n",
    "RMSE_r, tx_ok_20, tx_ok_10, R2_r = [], [], [], []\n",
    "\n",
    "best_dict = {\n",
    "    \"tx_ok_10\":0,\n",
    "    \"tx_ok_20\":0,\n",
    "    \"y_pred\": 0,\n",
    "    \"y_true\": 0,\n",
    "    \"RMSE\": 0,\n",
    "    \"R2\": 0,\n",
    "    \"R2_aj\": 0\n",
    "}\n",
    "\n",
    "Nr = 20\n",
    "for i in range(Nr):\n",
    "    rand_index = np.random.permutation(X.shape[0])\n",
    "    X = X[rand_index,:]\n",
    "    Y = Y[rand_index]\n",
    "\n",
    "    spt_point = int(2/3*X.shape[0])\n",
    "\n",
    "    X_train = X[:spt_point,:]\n",
    "    Y_train = Y[:spt_point]\n",
    "\n",
    "    X_test = X[spt_point:,:]\n",
    "    Y_test = Y[spt_point:]\n",
    "\n",
    "    X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "    X_test = np.c_[np.ones(X_test.shape[0]), X_test]\n",
    "    M = M = np.linalg.lstsq(X_train, Y_train, rcond = -1)[0]\n",
    "\n",
    "    Y_pred = np.dot(X_test, M)\n",
    "\n",
    "    count_10 = 0\n",
    "    count_20 = 0\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        \n",
    "        if np.abs(Y_test[i] - Y_pred[i]) <= 0.2*np.abs(Y_test[i]):\n",
    "            count_20 += 1\n",
    "        if np.abs(Y_test[i] - Y_pred[i]) <= 0.1*np.abs(Y_test[i]):\n",
    "            count_10 += 1\n",
    "\n",
    "    RMSE_r.append(RMSE(Y_test, Y_pred))\n",
    "    R2_r.append(R2(Y_test, Y_pred))\n",
    "    tx_ok_10.append(count_10/Y_test.shape[0])\n",
    "    tx_ok_20.append(count_20/Y_test.shape[0])\n",
    "\n",
    "    #Para ser a melhor rodada, deve ser melhor nas duas taxas de acerto\n",
    "    if (best_dict[\"tx_ok_10\"] <= count_10/X_test.shape[0]) & (best_dict[\"tx_ok_20\"] <= count_20/X_test.shape[0]):\n",
    "        best_dict[\"y_pred\"] = Y_pred\n",
    "        best_dict[\"y_true\"] = Y_test\n",
    "        best_dict[\"R2\"] = R2(Y_test, Y_pred)\n",
    "        best_dict[\"RMSE\"] = RMSE(Y_test, Y_pred)\n",
    "        best_dict[\"tx_ok_10\"] = count_10/X_test.shape[0]\n",
    "        best_dict[\"tx_ok_20\"] = count_20/X_test.shape[0]\n",
    "\n",
    "print(\"###### Resumo das {} Rodadas ######\".format(Nr))\n",
    "print('''Taxa de acerto para uma taxa de erro admssível de 20%:\n",
    "Média = {:.2%}, \n",
    "Desv. Pad. = {:.2%}, \n",
    "Máximo = {:.2%}, \n",
    "Mínimo = {:.2%}\\n'''.format(np.mean(tx_ok_20),\n",
    "    np.std(tx_ok_20), np.max(tx_ok_20), np.min(tx_ok_20)))\n",
    "\n",
    "print('''Taxa de acerto para uma taxa de erro admssível de 10%:\n",
    "Média = {:.2%}, \n",
    "Desv. Pad. = {:.2%}, \n",
    "Máximo = {:.2%}, \n",
    "Mínimo = {:.2%}\\n'''.format(np.mean(tx_ok_10),\n",
    "    np.std(tx_ok_10), np.max(tx_ok_10), np.min(tx_ok_10)))\n",
    "\n",
    "print('''R2:\n",
    "Média = {:.3f}, \n",
    "Desv. Pad. = {:.3f}, \n",
    "Máximo = {:.3f}, \n",
    "Mínimo = {:.3f}\\n'''.format(np.mean(R2_r),\n",
    "    np.std(R2_r), np.max(R2_r), np.min(R2_r)))\n",
    "\n",
    "print('''RMSE:\n",
    "Média = {:.3f}, \n",
    "Desv. Pad. = {:.3f}, \n",
    "Máximo = {:.3f}, \n",
    "Mínimo = {:.3f}'''.format(np.mean(RMSE_r),\n",
    "    np.std(RMSE_r), np.max(RMSE_r), np.min(RMSE_r)))\n",
    "\n",
    "print(\"\\n###### Melhor Rodada em relação as taxas de acerto para erros admissíveis de 10% e 20% ######\")\n",
    "print(\"Taxa de acerto para uma taxa de erro admssível de 20% = {:.2%}\".format(best_dict[\"tx_ok_20\"]))\n",
    "print(\"Taxa de acerto para uma taxa de erro admssível de 10% = {:.2%}\".format(best_dict[\"tx_ok_10\"]))\n",
    "print(\"R2 = {:.3f}\".format(best_dict[\"R2\"]))\n",
    "print(\"RMSE = {:.3f}\".format(best_dict[\"RMSE\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeh e Hsu (2018) apresentam o resultado da análise de regressão multivariada na Tabela 6 de seu artigo. Os resultados são apresentados de acordo com os círculos de abastecimento e demanda apresentados no Trabalho, são eles: Sindia, Danshuei, Wunshan e Beitou. Os resultados também são apresentados em termos da média obtida para cada um desses círculos de abastecimento e demanda.\n",
    "\n",
    "A base de dados disponibilizada refere-se as informações da círculo de abastecimento e demanda do Sindia, portanto os resultados obtidos nesse trabalho serão comparados aos resultados obtidos para essa região. Os autores destacam que a base de dados total foi divida aleatoriamente em 2/3 para treinamento e 1/3 para teste. As métricas apresentadas pelo autores correspondem a avaliação das predições para os dados de teste.\n",
    "\n",
    "Tendo em vista essa divisão aleatória realizada pelos autores, decidiu-se rodar o modelo de regressão linear múltipla 20 vezes, gerando uma estatística para essas 4 métricas. Para cada uma dessas rodadas, embaralhou-se a base de dados e realizou-se a separação entre dados de treino e dados de teste, segundo as proporções especificadas pelos autores.\n",
    "\n",
    "Foram comparadas 4 métricas: i) Taxa de acerto para um erro admissível de 20%, ii) Taxa de acerto para um erro admissível de 10%, iii) $R^{2}$ e iv) RMSE. A tabela abaixo apresenta as métricas para a rodada da regressão linear múltipla com melhor taxa de acerto para um erro tolerável de 10% e 20% e os valores obtidos por Yeh e Hsu (2018).\n",
    "\n",
    "|Métrica | Regressão Linear Múltipla | Yeh e Hsu (2018)|\n",
    "| :- | -: | -: |\n",
    "|i) | 78,99% | 78,00% |\n",
    "|ii) | 42,75% | 48,80% |\n",
    "|iii) | 0,630 | 0,627 |\n",
    "|iv) | 8,032  | 8,06 |\n",
    "\n",
    "Observa-se que o modelo implementado se aproximou dos resultados obtidos por Yeh e Hsu (2018). Exceto pela métrica ii), a a diferença no desempenho do modelo de Regressão Linear Múltipla e os resultados apresentado pelos referidos autores foram insignificantes. O desempenho do modelo implemetando para a métrica ii), por sua vez, ficou abaixo dos obtidos por Yeh e Hsu (2018) em cerca de 6%.\n",
    "\n",
    "Destaca-se que o desempenho superior ou inferior do modelo implementado em relação aos resultados de Yeh e Hsu (2018) é bastante influenciado pela divisão aleatória da base de dados, uma vez que haverá uma possível combinação de dados de treino e de teste que otimize ou reduza essas métricas.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extreme Learning Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###### Resumo das 10 Rodadas ######\n",
      "Taxa de acerto para uma taxa de erro admssível de 20%:\n",
      "Média = 71.30%, \n",
      "Desv. Pad. = 5.88%, \n",
      "Máximo = 82.61%, \n",
      "Mínimo = 62.32%\n",
      "\n",
      "Taxa de acerto para uma taxa de erro admssível de 10%:\n",
      "Média = 42.90%, \n",
      "Desv. Pad. = 6.48%, \n",
      "Máximo = 52.90%, \n",
      "Mínimo = 32.61%\n",
      "\n",
      "R2:\n",
      "Média = 0.612, \n",
      "Desv. Pad. = 0.080, \n",
      "Máximo = 0.763, \n",
      "Mínimo = 0.434\n",
      "\n",
      "RMSE:\n",
      "Média = 6.944, \n",
      "Desv. Pad. = 0.743, \n",
      "Máximo = 7.943, \n",
      "Mínimo = 5.426\n",
      "\n",
      "###### Melhor Rodada em relação as taxas de acerto para erros de 10% e 20% ######\n",
      "Taxa de acerto para uma taxa de erro admssível de 20% = 82.61%\n",
      "Taxa de acerto para uma taxa de erro admssível de 10% = 52.90%\n",
      "R2 = 0.763\n",
      "RMSE = 5.426\n",
      "\n",
      "Tempo de Calibração e Validação = 0.271 segundos, Rodadas = 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def act_fun(u, fun):\n",
    "\n",
    "    if fun == \"step\":\n",
    "        u[np.where(u >= 0)] = 1\n",
    "        u[np.where(u < 0)] = 0\n",
    "\n",
    "    elif fun == \"tanh\":\n",
    "        u = np.array(list(map(lambda x: (1-np.exp(-x))/(1+np.exp(-x)), u)))\n",
    "    \n",
    "    elif fun == \"log\":\n",
    "        u = np.array(list(map(lambda x: 1/(1+np.exp(-x)), u)))\n",
    "    \n",
    "    return u \n",
    "\n",
    "def norm_data(x):\n",
    "\n",
    "    for i in range(x.shape[1]):\n",
    "        x[:,i] = x[:,i]/x[:,i].max()\n",
    "        \n",
    "    return x\n",
    "\n",
    "def R2(y_true, y_pred):\n",
    "\n",
    "    coef = 1 - (np.power(y_true-y_pred,2).sum()/np.power(y_true-y_true.mean(),2).sum())\n",
    "    \n",
    "    return coef\n",
    "\n",
    "def RMSE_calc(y_true, y_pred):\n",
    "\n",
    "    coef = np.power((np.power(y_true - y_pred, 2).sum())/y_true.shape[0], 0.5)\n",
    "\n",
    "    return coef\n",
    "\n",
    "data = pd.read_excel(\"Real estate valuation data set.xlsx\", index_col = 0)\n",
    "\n",
    "X = data.iloc[:, 0:6].to_numpy()\n",
    "\n",
    "Y = data.iloc[:, -1].to_numpy()\n",
    "\n",
    "X = norm_data(X)\n",
    "Y = norm_data(np.expand_dims(Y,1))\n",
    "\n",
    "fun_type = \"log\"\n",
    "Nr = 10\n",
    "q = 5\n",
    "RMSE_r = []\n",
    "R2_r = []\n",
    "R2aj_r = []\n",
    "tx_ok_20 = []\n",
    "tx_ok_10 = []\n",
    "\n",
    "best_dict = {\n",
    "    \"tx_ok_10\":0,\n",
    "    \"tx_ok_20\":0,\n",
    "    \"y_pred\": 0,\n",
    "    \"y_true\": 0,\n",
    "    \"RMSE\": 0,\n",
    "    \"R2\": 0,\n",
    "    \"R2_aj\": 0\n",
    "}\n",
    "tic = time.perf_counter()\n",
    "for r in range(Nr):\n",
    "    rand_index = np.random.permutation(X.shape[0])\n",
    "\n",
    "    X = X[rand_index,:]\n",
    "    Y = Y[rand_index]\n",
    "\n",
    "    spt_point = int(2/3*X.shape[0])\n",
    "    X_train = X[:spt_point,:]\n",
    "    Y_train = Y[:spt_point]\n",
    "\n",
    "    X_test = X[spt_point:,:]\n",
    "    Y_test = Y[spt_point:]\n",
    "\n",
    "    W = np.random.normal(loc = 0, scale = 0.1, size = (q, X.shape[1]+1))\n",
    "\n",
    "    Z = []\n",
    "\n",
    "    for i in range(X_train.shape[0]):\n",
    "        x = np.append(-1, X_train[i,:])\n",
    "        U = np.dot(W, x)\n",
    "        z = act_fun(U, fun_type)\n",
    "        z = np.append(-1, z)\n",
    "        Z.append(z)\n",
    "    Z = np.array(Z)\n",
    "    M = np.dot(np.linalg.pinv(Z), Y_train)\n",
    "\n",
    "    count_20 = 0\n",
    "    count_10 = 0\n",
    "    y_pred = []\n",
    "    RMSE = 0\n",
    "    for j in range(X_test.shape[0]):\n",
    "        x = np.append(-1, X_test[j,:])\n",
    "        U1 = np.dot(W, x)\n",
    "        z = act_fun(U1, fun_type)\n",
    "        z = np.append(-1, z)\n",
    "        y = np.dot(z, M)\n",
    "        y_pred.append(y)\n",
    "        RMSE = RMSE + RMSE_calc(Y_test[j], y)\n",
    "        if np.abs(Y_test[j] - y) <= 0.2*np.abs(Y_test[j]):\n",
    "            count_20 += 1\n",
    "        if np.abs(Y_test[j] - y) <= 0.1*np.abs(Y_test[j]):\n",
    "            count_10 += 1\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    RMSE_r.append(RMSE)\n",
    "    R2_r.append(R2(Y_test, y_pred))\n",
    "    tx_ok_20.append(count_20/X_test.shape[0])\n",
    "    tx_ok_10.append(count_10/X_test.shape[0])\n",
    "    \n",
    "    #Para ser a melhor rodada, deve ser melhor nas duas taxas de acerto\n",
    "    if (best_dict[\"tx_ok_10\"] <= count_10/X_test.shape[0]) & (best_dict[\"tx_ok_20\"] <= count_20/X_test.shape[0]):\n",
    "        best_dict[\"y_pred\"] = y_pred\n",
    "        best_dict[\"y_true\"] = Y_test\n",
    "        best_dict[\"R2\"] = R2(Y_test, y_pred)\n",
    "        best_dict[\"RMSE\"] = RMSE\n",
    "        best_dict[\"tx_ok_10\"] = count_10/X_test.shape[0]\n",
    "        best_dict[\"tx_ok_20\"] = count_20/X_test.shape[0]\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(\"\\n###### Resumo das {} Rodadas ######\".format(Nr))\n",
    "print('''Taxa de acerto para uma taxa de erro admssível de 20%:\n",
    "Média = {:.2%}, \n",
    "Desv. Pad. = {:.2%}, \n",
    "Máximo = {:.2%}, \n",
    "Mínimo = {:.2%}\\n'''.format(np.mean(tx_ok_20),np.std(tx_ok_20), np.max(tx_ok_20), np.min(tx_ok_20)))\n",
    "print('''Taxa de acerto para uma taxa de erro admssível de 10%:\n",
    "Média = {:.2%}, \n",
    "Desv. Pad. = {:.2%}, \n",
    "Máximo = {:.2%}, \n",
    "Mínimo = {:.2%}\\n'''.format(np.mean(tx_ok_10), np.std(tx_ok_10), np.max(tx_ok_10), np.min(tx_ok_10)))\n",
    "print('''R2:\n",
    "Média = {:.3f}, \n",
    "Desv. Pad. = {:.3f}, \n",
    "Máximo = {:.3f}, \n",
    "Mínimo = {:.3f}\\n'''.format(np.mean(R2_r), np.std(R2_r), np.max(R2_r), np.min(R2_r)))\n",
    "print('''RMSE:\n",
    "Média = {:.3f}, \n",
    "Desv. Pad. = {:.3f}, \n",
    "Máximo = {:.3f}, \n",
    "Mínimo = {:.3f}'''.format(np.mean(RMSE_r), np.std(RMSE_r), np.max(RMSE_r), np.min(RMSE_r)))\n",
    "\n",
    "print(\"\\n###### Melhor Rodada em relação as taxas de acerto para erros de 10% e 20% ######\")\n",
    "print(\"Taxa de acerto para uma taxa de erro admssível de 20% = {:.2%}\".format(best_dict[\"tx_ok_20\"]))\n",
    "print(\"Taxa de acerto para uma taxa de erro admssível de 10% = {:.2%}\".format(best_dict[\"tx_ok_10\"]))\n",
    "print(\"R2 = {:.3f}\".format(best_dict[\"R2\"]))\n",
    "print(\"RMSE = {:.3f}\".format(best_dict[\"RMSE\"]))\n",
    "\n",
    "print(\"\\nTempo de Calibração e Validação = {:.3f} segundos, Rodadas = {}\".format(toc - tic, Nr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeh e Hsu (2018) apresentam o resultado da predição dos modelos de redes neurais na Tabela 7 de seu artigo. Os resultados são apresentados de acordo com os círculos de abastecimento e demanda apresentados no Trabalho, são eles: Sindia, Danshuei, Wunshan e Beitou. Os resultados também são apresentados em termos da média obtida para cada um desses círculos de abastecimento e demanda.\n",
    "\n",
    "A base de dados disponibilizada refere-se as informações da círculo de abastecimento e demanda do Sindia, portanto os resultados obtidos nesse trabalho serão comparados aos resultados obtidos para essa região. Yeh e Hsu (2018) destacam que a base de dados total foi divida aleatoriamente em 2/3 para treinamento e 1/3 para teste. As métricas apresentadas pelo autores correspondem a avaliação das predições para os dados de teste.\n",
    "\n",
    "A ELM implementada possui a seguinte arquitetura (6, 5, 1). Adotou o número de neurônio ocultos $(q = 5)$ igual ao especificado por Yeh e Hsu (2018). A ELM foi rodada 10 vezes e, para cada uma dessas rodadas, embaralhou-se a base de dados e realizou-se a separação entre dados de treino e dados de teste, segundo as proporções especificadas pelos autores. Cabe destacar que esses dados de treino e teste foram previamente normalizados, trazendo todos os valores para uma escala comum sem distorcer as diferenças nos intervalos de valores. Como foi adotado a função de ativação logística, essa nova escala comum adotada foi $x_{norm} \\in [0,1]$\n",
    "\n",
    "Foram comparadas 4 métricas: i) Taxa de acerto para um erro admissível de 20%, ii) Taxa de acerto para um erro admissível de 10%, iii) $R^{2}$ e iv) RMSE. A tabela abaixo apresenta as métricas para a rodada da ELM com melhor taxa de acerto para um erro tolerável de 10% e 20% e os valores obtidos por Yeh e Hsu (2018).\n",
    "\n",
    "|Métrica | Extreme Learning Machine | Yeh e Hsu (2018)|\n",
    "| :- | -: | -: |\n",
    "|i) | 82,61% | 78,00% |\n",
    "|ii) | 52,90% | 48,80% |\n",
    "|iii) | 0,763 | 0,627 |\n",
    "|iv) | 5,426  | 8,06 |\n",
    "\n",
    "Observa-se que a rede ELM implementada apresentou um desempenho superior à MLP implementada pelos autores para todas as métricas avaliadas. Esse melhor desempenho pode ser oriundo da aleatoriedade implementada na separação da base de treino e teste, existindo uma combinação de dados de treino e de teste que otimize essas métricas. Além do melhor desempenho, destaca-se a velocidade de treinamento e validação do algoritmo implementado, cerca de 0,271 segundos.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###### Resumo das 10 Rodadas ######\n",
      "Taxa de acerto para uma taxa de erro admssível de 20%:\n",
      "Média = 67.68%, \n",
      "Desv. Pad. = 11.39%, \n",
      "Máximo = 80.43%, \n",
      "Mínimo = 38.41%\n",
      "\n",
      "Taxa de acerto para uma taxa de erro admssível de 10%:\n",
      "Média = 38.70%, \n",
      "Desv. Pad. = 7.96%, \n",
      "Máximo = 48.55%, \n",
      "Mínimo = 18.12%\n",
      "\n",
      "R2:\n",
      "Média = 0.492, \n",
      "Desv. Pad. = 0.204, \n",
      "Máximo = 0.686, \n",
      "Mínimo = -0.034\n",
      "\n",
      "RMSE:\n",
      "Média = 7.771, \n",
      "Desv. Pad. = 1.452, \n",
      "Máximo = 11.351, \n",
      "Mínimo = 6.277\n",
      "\n",
      "###### Melhor Rodada em relação as taxas de acerto para erros admissíveis de 10% e 20% ######\n",
      "Taxa de acerto para uma taxa de erro admssível de 20% = 80.43%\n",
      "Taxa de acerto para uma taxa de erro admssível de 10% = 44.20%\n",
      "R2 = 0.614\n",
      "RMSE = 6.281\n",
      "\n",
      "Tempo de Calibração e Validação = 1675.135 segundos, Rodadas = 10, Épocas = 1500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "import time\n",
    "\n",
    "def act_fun(u, fun):\n",
    "    action_fun = namedtuple(\"act_fun\", [\"f\", \"df\"])\n",
    "    if fun == \"step\":\n",
    "        u[np.where(u >= 0)] = 1\n",
    "        u[np.where(u < 0)] = 0\n",
    "        du = np.nan\n",
    "    elif fun == \"tanh\":\n",
    "        u = np.array(list(map(lambda x: (1-np.exp(-x))/(1+np.exp(-x)), u)))\n",
    "        du = 0.5*(1-np.power(u,2)) + 0.05\n",
    "    elif fun == \"log\":\n",
    "        u = np.array(list(map(lambda x: 1/(1+np.exp(-x)), u)), dtype = \"float\")\n",
    "        du = u*(1-u)\n",
    "    return (action_fun(f = u, df = du))\n",
    "\n",
    "def norm_data(x):\n",
    "\n",
    "    for i in range(x.shape[1]):\n",
    "        x[:,i] = x[:,i]/x[:,i].max()\n",
    "        # x[:,i] = 2*((x[:,i] - x[:,i].min())/(x[:,i].max() - x[:,i].min())) - 1\n",
    "        #x_norm = 2*((x - x.min())/(x.max() - x.min()) - 1\n",
    "    return x\n",
    "\n",
    "def R2(y_true, y_pred):\n",
    "\n",
    "    coef = 1 - (np.power(y_true-y_pred,2).sum()/np.power(y_true-y_true.mean(),2).sum())\n",
    "\n",
    "    return (coef)\n",
    "\n",
    "def RMSE_calc(y_true, y_pred):\n",
    "\n",
    "    coef = np.power((np.power(y_true - y_pred, 2).sum())/y_true.shape[0], 0.5)\n",
    "\n",
    "    return coef\n",
    "\n",
    "def Hardamad_Prod(a, b):\n",
    "    \n",
    "    prod = np.array([np.multiply(x,y) for x, y in zip(a,b)])\n",
    "\n",
    "    return prod\n",
    "\n",
    "data = pd.read_excel(\"Real estate valuation data set.xlsx\", index_col = 0)\n",
    "\n",
    "X_real = data.iloc[:, 0:6].to_numpy()\n",
    "\n",
    "Y_real = data.iloc[:, -1].to_numpy()\n",
    "\n",
    "X = norm_data(X_real)\n",
    "Y = norm_data(np.expand_dims(Y_real,1))\n",
    "\n",
    "fun_type = \"log\"\n",
    "Nr = 10\n",
    "q = 5\n",
    "eta = 0.6\n",
    "Ne = 1500\n",
    "mon = 0.9\n",
    "\n",
    "RMSE_r = []\n",
    "R2_r = []\n",
    "tx_ok_20 = []\n",
    "tx_ok_10 = []\n",
    "\n",
    "best_dict = {\n",
    "    \"tx_ok_10\":0,\n",
    "    \"tx_ok_20\":0,\n",
    "    \"y_pred\": 0,\n",
    "    \"y_true\": 0,\n",
    "    \"RMSE\": 0,\n",
    "    \"R2\": 0,\n",
    "    \"R2_aj\": 0\n",
    "}\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "for r in range(Nr):\n",
    "    rand_index = np.random.permutation(X.shape[0])\n",
    "\n",
    "    X = X[rand_index,:]\n",
    "    Y = Y[rand_index]\n",
    "\n",
    "    spt_point = int(2/3*X.shape[0])\n",
    "    X_train = X[:spt_point,:]\n",
    "    Y_train = Y[:spt_point,:]\n",
    "\n",
    "    X_test = X[spt_point:,:]\n",
    "    Y_test = Y[spt_point:,:]\n",
    "\n",
    "    W = {\n",
    "        0: np.random.rand(q, X_train.shape[1]+1)*0.01,\n",
    "        1: np.random.rand(Y_train.shape[1], q+1)*0.01\n",
    "    }\n",
    "    W_old = W.copy()\n",
    "\n",
    "    for e in range(Ne):\n",
    "        rand_index = np.random.permutation(X_train.shape[0])\n",
    "        X_train = X_train[rand_index,:]\n",
    "        Y_train = Y_train[rand_index,:]\n",
    "        \n",
    "\n",
    "        for i in range(X_train.shape[0]):\n",
    "            x = np.append(-1, X_train[i,:])\n",
    "            U1 = np.dot(W[0], x)\n",
    "            z, dz = act_fun(U1, fun_type)\n",
    "            z = np.append(-1, z)\n",
    "            U2 = np.dot(W[1], z)\n",
    "            y, dy = act_fun(U2, fun_type)\n",
    "\n",
    "            err = Y_train[i,:] - y\n",
    "            \n",
    "            err = np.expand_dims(Hardamad_Prod(err, dy), 1)\n",
    "            x = np.expand_dims(x,1)\n",
    "            z = np.expand_dims(z,1)\n",
    "\n",
    "            W_aux = W.copy()\n",
    "            \n",
    "            DDi = Hardamad_Prod(dz, np.dot(W[1][:,1:].T, err))\n",
    "\n",
    "            W[0] = W[0] + eta*np.dot(DDi, x.T) + mon*(W[0] - W_old[0])\n",
    "            W[1] = W[1] + eta*np.dot(err, z.T) + mon*(W[1] - W_old[1])\n",
    "\n",
    "            W_old = W_aux.copy()\n",
    "\n",
    "    RMSE_test = 0\n",
    "    count_20 = 0\n",
    "    count_10 = 0\n",
    "    y_pred = []\n",
    "    for j in range(X_test.shape[0]):\n",
    "        x = np.append(-1, X_test[j,:])\n",
    "        U1 = np.dot(W[0],x)\n",
    "        z = act_fun(U1, fun_type).f\n",
    "        z = np.append(-1, z)\n",
    "        U2 = np.dot(W[1], z)\n",
    "        y = act_fun(U2, fun_type).f\n",
    "        y_pred.append(y)\n",
    "        err = Y_test[j,:] - y\n",
    "\n",
    "        RMSE_test = RMSE_test + RMSE_calc(Y_test[j,:], y)\n",
    "\n",
    "        if np.abs(err) <= 0.2*np.abs(Y_test[j,:]):\n",
    "            count_20 += 1\n",
    "        if np.abs(err) <= 0.1*np.abs(Y_test[j,:]):\n",
    "            count_10 += 1\n",
    "    \n",
    "    RMSE_r.append(RMSE_test)\n",
    "    R2_r.append(R2(Y_test, y_pred))\n",
    "    tx_ok_20.append(count_20/X_test.shape[0])\n",
    "    tx_ok_10.append(count_10/X_test.shape[0])\n",
    "\n",
    "    #Para ser a melhor rodada, deve ser melhor nas duas taxas de acerto\n",
    "    if (best_dict[\"tx_ok_10\"] <= count_10/X_test.shape[0]) & (best_dict[\"tx_ok_20\"] <= count_20/X_test.shape[0]):\n",
    "        best_dict[\"y_pred\"] = y_pred\n",
    "        best_dict[\"y_true\"] = Y_test\n",
    "        best_dict[\"R2\"] = R2(Y_test, y_pred)\n",
    "        best_dict[\"RMSE\"] = RMSE_test\n",
    "        best_dict[\"tx_ok_10\"] = count_10/X_test.shape[0]\n",
    "        best_dict[\"tx_ok_20\"] = count_20/X_test.shape[0]\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(\"\\n###### Resumo das {} Rodadas ######\".format(Nr))\n",
    "print('''Taxa de acerto para uma taxa de erro admssível de 20%:\n",
    "Média = {:.2%}, \n",
    "Desv. Pad. = {:.2%}, \n",
    "Máximo = {:.2%}, \n",
    "Mínimo = {:.2%}\\n'''.format(np.mean(tx_ok_20),np.std(tx_ok_20), np.max(tx_ok_20), np.min(tx_ok_20)))\n",
    "print('''Taxa de acerto para uma taxa de erro admssível de 10%:\n",
    "Média = {:.2%}, \n",
    "Desv. Pad. = {:.2%}, \n",
    "Máximo = {:.2%}, \n",
    "Mínimo = {:.2%}\\n'''.format(np.mean(tx_ok_10), np.std(tx_ok_10), np.max(tx_ok_10), np.min(tx_ok_10)))\n",
    "print('''R2:\n",
    "Média = {:.3f}, \n",
    "Desv. Pad. = {:.3f}, \n",
    "Máximo = {:.3f}, \n",
    "Mínimo = {:.3f}\\n'''.format(np.mean(R2_r), np.std(R2_r), np.max(R2_r), np.min(R2_r)))\n",
    "print('''RMSE:\n",
    "Média = {:.3f}, \n",
    "Desv. Pad. = {:.3f}, \n",
    "Máximo = {:.3f}, \n",
    "Mínimo = {:.3f}'''.format(np.mean(RMSE_r), np.std(RMSE_r), np.max(RMSE_r), np.min(RMSE_r)))\n",
    "\n",
    "print(\"\\n###### Melhor Rodada em relação as taxas de acerto para erros admissíveis de 10% e 20% ######\")\n",
    "print(\"Taxa de acerto para uma taxa de erro admssível de 20% = {:.2%}\".format(best_dict[\"tx_ok_20\"]))\n",
    "print(\"Taxa de acerto para uma taxa de erro admssível de 10% = {:.2%}\".format(best_dict[\"tx_ok_10\"]))\n",
    "print(\"R2 = {:.3f}\".format(best_dict[\"R2\"]))\n",
    "print(\"RMSE = {:.3f}\".format(best_dict[\"RMSE\"]))\n",
    "\n",
    "print(\"\\nTempo de Calibração e Validação = {:.3f} segundos, Rodadas = {}, Épocas = {}\".format(toc - tic, Nr, Ne))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeh e Hsu (2018) apresentam o resultado da predição dos modelos de redes neurais na Tabela 7 de seu artigo. Os resultados são apresentados de acordo com os círculos de abastecimento e demanda apresentados no Trabalho, são eles: Sindia, Danshuei, Wunshan e Beitou. Os resultados também são apresentados em termos da média obtida para cada um desses círculos de abastecimento e demanda.\n",
    "\n",
    "A base de dados disponibilizadas refere-se as informações da círculo de abastecimento e demanda do Sindia, portanto os resultados obtidos nesse trabalho serão comparados aos resultados obtidos para essa região. Yeh e Hsu (2018) destacam que a base de dados total foi divida aleatoriamente em 2/3 para treinamento e 1/3 para teste. As métricas apresentadas pelo autores correspondem a avaliação das predições para os dados de teste.\n",
    "\n",
    "A MLP implementada possui uma a seguinte arquitetura (6, 5, 1). Adotou-se o número de neurônio ocultos $(q = 5)$, taxa de aprendizado $(\\eta = 0,6)$ e o número de épocas $(Ne = 1500)$ iguais ao especificado por Yeh e Hsu (2018). Yeh e Hsu (2018) não destacam a utilização do fator de momento, todavia optou-se pela sua utilização na MLP implementada no presente projeto, visando uma modificação mais estável dos pesos sinápticos ao longo do treinamento da rede. O fator de momento considerado foi igual a $0,9$\n",
    "\n",
    "Tendo em vista a divisão aleatória da base de dados total em dados de treino e teste realizada por Yeh e Hsu (2018), a MLP implementada foi rodada 10 vezes e, para cada uma dessas rodadas, embaralhou-se a base de dados total e realizou-se a separação entre dados de treino e dados de teste, segundo as proporções especificadas pelos autores.\n",
    "\n",
    "Da mesma forma que para a ELM, a base de dados total foi previamente normalizada antes do treinamento e validação da MLP, trazendo todos os valores para uma escala comum sem distorcer as diferenças nos intervalos de valores. Como foi adotado a função de ativação logística, essa nova escala comum adotada foi $x_{norm} \\in [0,1]$. Busca-se, com esse processo, melhorar a estabilidade e convergência do processo de aprendizado.\n",
    "\n",
    "Foram comparadas 4 métricas: i) Taxa de acerto para um erro admissível de 20%, ii) Taxa de acerto para um erro admissível de 10%, iii) $R^{2}$ e iv) RMSE. A tabela abaixo apresenta as métricas para a rodada da MLP com melhor taxa de acerto para um erro de 10% e 20% e os valores obtidos por Yeh e Hsu (2018).\n",
    "\n",
    "|Métrica | MLP (6,5,1) | Yeh e Hsu (2018)|\n",
    "| :- | -: | -: |\n",
    "|i) | 80,43% | 78,00% |\n",
    "|ii) | 44,20% | 48,80% |\n",
    "|iii) | 0,614 | 0,627 |\n",
    "|iv) | 6,281  | 8,06 |\n",
    "\n",
    "Observa-se que a MLP implementada teve resultados próximos aos obtidos por Yeh e Hsu (2018). A MLP implementada teve um desempenho um pouco melhor para as métricas i) e iv), ficando atrás nas métricas ii) e iii). Apesar da arquitetura semelhante da MLP implementada no presente trabalho e a implementada por Yeh e Hsu (2018), destaca-se que a divisão aleatória da base de dados pode gerar combinações de dados de treino e de teste capazes de dificultar ou melhorar o treinamento e generalização da rede neural. Como pode ser observado na estatística das métricas adotadas para as 10 rodadas, o $R^{2}$ teve um valor mínimo de -0,034 e um valor máximo de 0,614, evidenciando a influência dessa divisão aleatória da base de dados no desempenho da rede neural.\n",
    "\n",
    "Comparando a MLP implementada com a ELM implementada no item anterior, pode-se constatar que a ELM teve um melhor desempenho em todas as métricas avaliadas, todavia, a influência da divisão aleatória da base de dados também é válida para essa comparação. Além dessas métricas, observa-se um tempo de treinamento e validação consideravelmente menor para ELM (0,271 segundos) em relação a MLP (1675,135 segundos), o que torna a ELM bem mais atrativa para solução do problema proposto.\n",
    "\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Referências\n",
    "Yeh, I-C.; Hsu, T-K. Building real estate valuation models with comparative approachthrough case-based reasoning, **Applied Soft Computing**, 65, 2018, p. 260-271, doi: 10.1016/j.asoc.2018.01.029\n",
    "***\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Doutorado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
